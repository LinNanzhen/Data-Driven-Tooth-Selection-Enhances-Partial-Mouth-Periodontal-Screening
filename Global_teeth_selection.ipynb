{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import contextlib\n",
    "import io\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "           \n",
    "# ================== Library Imports ==================\n",
    "try:\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Integer, Categorical\n",
    "    SKOPT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKOPT_AVAILABLE = False\n",
    "    print(\"Warning: scikit-optimize is not installed. Bayesian optimization will not be available.\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"Warning: shap is not installed. Model interpretation will not be available.\")\n",
    "\n",
    "try:\n",
    "    import xlsxwriter\n",
    "    XLSXWRITER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XLSXWRITER_AVAILABLE = False\n",
    "    print(\"Warning: xlsxwriter is not installed. Saving SHAP values to Excel will not be available.\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import with proper error handling\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ================== Configuration ==================\n",
    "class Config:\n",
    "    BASE_DIR = Path('.')\n",
    "    DATA_PATH = BASE_DIR / \"cleaned_data.csv\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"Global_teeth_selection\"\n",
    "    TARGET_COLUMN = 'perio_label_cdc'\n",
    "    AGE_COLUMN = 'RIDAGEYR'\n",
    "    WEIGHT_COLUMN = 'WTMEC2YR'\n",
    "    MIN_AGE = 35\n",
    "    RANDOM_SEEDS = [42, 123, 456, 999, 2025]\n",
    "    CV_FOLDS = 5\n",
    "    INTERPROXIMAL_SITES = {'D', 'S', 'P', 'A'}\n",
    "    CLASS_LABELS = {0: 'Healthy', 1: 'Other', 2: 'Severe'}\n",
    "    \n",
    "    TOP_FEATURES_COUNT = 10\n",
    "    SHAP_SAMPLE_SIZE = 1000\n",
    "    SHAP_PLOT_MAX_DISPLAY = 20\n",
    "\n",
    "    CPI_RAMFJORD_TOOTH_NUMBERS = {\n",
    "        'Ramfjord': ['16', '14', '21', '24', '26', '36', '34', '41', '44', '46'],\n",
    "        'CPI': [ '11', '16', '17', '26', '27', '31', '36', '37', '46', '47']\n",
    "    }\n",
    "    \n",
    "    NHANES_TO_FDI_MAPPING = {\n",
    "        '01': '18', '02': '17', '03': '16', '04': '15', '05': '14', '06': '13', '07': '12', '08': '11',\n",
    "        '09': '21', '10': '22', '11': '23', '12': '24', '13': '25', '14': '26', '15': '27', '16': '28',\n",
    "        '17': '38', '18': '37', '19': '36', '20': '35', '21': '34', '22': '33', '23': '32', '24': '31',\n",
    "        '25': '41', '26': '42', '27': '43', '28': '44', '29': '45', '30': '46', '31': '47', '32': '48'\n",
    "    }\n",
    "\n",
    "    # Optimized Bayesian Hyperparameter Space\n",
    "    BAYESIAN_HYPERPARAMETER_SPACES = {\n",
    "        'XGBoost': {\n",
    "            'n_estimators': Integer(1000, 1300),  \n",
    "            'max_depth': Integer(2, 4),  \n",
    "            'learning_rate': Real(0.05, 0.15, 'log-uniform'),  \n",
    "            'subsample': Real(0.7, 0.9, 'uniform'),  \n",
    "            'colsample_bytree': Real(0.85, 0.95, 'uniform'),  \n",
    "            'gamma': Real(0.2, 0.8, 'uniform'),  \n",
    "            'reg_alpha': Real(1e-3, 1e-2, 'log-uniform'),  \n",
    "            'reg_lambda': Real(1e-3, 1e-2, 'log-uniform'),  \n",
    "            'min_child_weight': Integer(8, 12)  \n",
    "        },\n",
    "        'LightGBM': {\n",
    "            'n_estimators': Integer(800, 1200),  \n",
    "            'max_depth': Integer(1, 3),  \n",
    "            'num_leaves': Integer(80, 150),  \n",
    "            'learning_rate': Real(0.08, 0.20, 'log-uniform'),  \n",
    "            'subsample': Real(0.7, 0.9, 'uniform'),  \n",
    "            'colsample_bytree': Real(0.6, 0.8, 'uniform'),  \n",
    "            'reg_alpha': Real(1e-5, 1e-3, 'log-uniform'),  \n",
    "            'reg_lambda': Real(5.0, 15.0, 'log-uniform'),  \n",
    "            'min_child_samples': Integer(10, 25)  \n",
    "        }\n",
    "    }\n",
    "\n",
    "    BAYESIAN_N_ITER = 30\n",
    "\n",
    "Config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================== Utility Functions ==================\n",
    "def create_model(model_name, random_state=42, **kwargs):\n",
    "    \"\"\"Creates a model instance based on the model name.\"\"\"\n",
    "    if model_name == 'XGBoost':\n",
    "        if not XGB_AVAILABLE:\n",
    "            raise ImportError(\"XGBoost is not available\")\n",
    "        return xgb.XGBClassifier(\n",
    "            objective='multi:softprob', \n",
    "            random_state=random_state, \n",
    "            use_label_encoder=False, \n",
    "            eval_metric='mlogloss', \n",
    "            n_jobs=1, \n",
    "            verbosity=0, \n",
    "            **kwargs\n",
    "        )\n",
    "    elif model_name == 'LightGBM':\n",
    "        if not LGB_AVAILABLE:\n",
    "            raise ImportError(\"LightGBM is not available\")\n",
    "        return lgb.LGBMClassifier(\n",
    "            objective='multiclass', \n",
    "            random_state=random_state, \n",
    "            n_jobs=-1,  \n",
    "            verbose=-1,\n",
    "            class_weight= None,\n",
    "            verbosity=-1,\n",
    "            **kwargs\n",
    "        )\n",
    "    else: \n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "# ================== Data Processor ==================\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.pd_columns = []\n",
    "        self.cal_columns = []\n",
    "\n",
    "    def load_and_preprocess(self, filepath):\n",
    "        print(f\"Loading data from: {filepath}\")\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, low_memory=False)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Data file not found at {filepath}. Please ensure 'cleaned_data.csv' is in the correct directory.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        required_cols = [Config.AGE_COLUMN, Config.WEIGHT_COLUMN]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing required columns: {missing_cols}\")\n",
    "            for col in missing_cols:\n",
    "                if col == Config.WEIGHT_COLUMN: df[col] = 1.0\n",
    "                elif col == Config.AGE_COLUMN: df[col] = 40\n",
    "        \n",
    "        print(f\"Initial sample size: {len(df)}\")\n",
    "        df = df[df[Config.AGE_COLUMN] >= Config.MIN_AGE].copy()\n",
    "        print(f\"Sample size after age filtering (>= {Config.MIN_AGE}): {len(df)}\")\n",
    "        \n",
    "        initial_weighted_size = len(df)\n",
    "        df = df[(df[Config.WEIGHT_COLUMN].notna()) & (df[Config.WEIGHT_COLUMN] > 0)].copy()\n",
    "        print(f\"Sample size after weight filtering: {len(df)} (removed {initial_weighted_size - len(df)} records)\")\n",
    "        \n",
    "        df = self._identify_periodontal_features(df)\n",
    "        df = self._handle_missing_values(df)\n",
    "        df = self._apply_cdc_classification(df)\n",
    "        \n",
    "        print(\"\\nData preprocessing complete.\")\n",
    "        return df\n",
    "\n",
    "    def _identify_periodontal_features(self, df):\n",
    "        pd_pattern = r'^OHX\\d{2}PC[ADSP]$'\n",
    "        cal_pattern = r'^OHX\\d{2}LA[ADSP]$'\n",
    "        self.pd_columns = sorted([c for c in df.columns if re.search(pd_pattern, c)])\n",
    "        self.cal_columns = sorted([c for c in df.columns if re.search(cal_pattern, c)])\n",
    "        for col in self.pd_columns + self.cal_columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        return df\n",
    "\n",
    "    def _handle_missing_values(self, df):\n",
    "        for col in self.pd_columns + self.cal_columns:\n",
    "            df[col] = df[col].fillna(np.nan)\n",
    "        return df\n",
    "\n",
    "    def _apply_cdc_classification(self, df):\n",
    "        pd_cols = self.pd_columns  # PD （OHX##PC[ADSP]）\n",
    "        cal_cols = self.cal_columns # CAL （OHX##LA[ADSP]）\n",
    "        impute_cols = pd_cols + cal_cols\n",
    "        df_imputed = df[impute_cols].copy()\n",
    "        df_imputed.replace(99, np.nan, inplace=True)\n",
    "\n",
    "        #  Construct the Max of Adjacent Sites per Tooth (One Table Each for PPD and CAL)\n",
    "        tooth_prefixes = sorted({c[:5] for c in impute_cols}) \n",
    "        tooth_pd_cols = {tp: [] for tp in tooth_prefixes}\n",
    "        tooth_cal_cols = {tp: [] for tp in tooth_prefixes}\n",
    "\n",
    "        for col in pd_cols:\n",
    "            if col[-1] in Config.INTERPROXIMAL_SITES:\n",
    "                tooth_pd_cols[col[:5]].append(col)\n",
    "        for col in cal_cols:\n",
    "            if col[-1] in Config.INTERPROXIMAL_SITES:\n",
    "                tooth_cal_cols[col[:5]].append(col)\n",
    "\n",
    "        tooth_pd_max = {}\n",
    "        tooth_cal_max = {}\n",
    "        for tp in tooth_prefixes:\n",
    "            cols_pd = tooth_pd_cols[tp]\n",
    "            cols_cal = tooth_cal_cols[tp]\n",
    "            tooth_pd_max[tp]  = df_imputed[cols_pd].max(axis=1) if cols_pd else pd.Series(np.nan, index=df.index)\n",
    "            tooth_cal_max[tp] = df_imputed[cols_cal].max(axis=1) if cols_cal else pd.Series(np.nan, index=df.index)\n",
    "\n",
    "        tooth_pd_max_df  = pd.DataFrame(tooth_pd_max)\n",
    "        tooth_cal_max_df = pd.DataFrame(tooth_cal_max)\n",
    "\n",
    "        # Count the 'Number of Teeth Meeting the Threshold' (Different Tooth Constraints)\n",
    "        def count_teeth_ge(mat: pd.DataFrame, thr: float) -> pd.Series:\n",
    "            return (mat >= thr).sum(axis=1)\n",
    "\n",
    "        n_CAL3 = count_teeth_ge(tooth_cal_max_df, 3.0)\n",
    "        n_CAL4 = count_teeth_ge(tooth_cal_max_df, 4.0)\n",
    "        n_CAL6 = count_teeth_ge(tooth_cal_max_df, 6.0)\n",
    "        n_PPD4 = count_teeth_ge(tooth_pd_max_df,  4.0)\n",
    "        n_PPD5 = count_teeth_ge(tooth_pd_max_df,  5.0)\n",
    "\n",
    "        # Classification Logic (Prioritize Severe Assessment, Followed by Moderate, Then Mild)\n",
    "        severe = (n_CAL6 >= 2) & (n_PPD5 >= 1) \n",
    "\n",
    "        other = ((~severe) & (n_CAL3 >= 2) & ((n_PPD4 >= 2) | (n_PPD5 >= 1)))\n",
    "        \n",
    "        label = np.where(severe, 2, np.where(other, 1, 0)).astype(int)\n",
    "\n",
    "        df[Config.TARGET_COLUMN] = label\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_max_features(self, df, column_list, feature_type):\n",
    "        if not column_list:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "        \n",
    "        data_for_agg = df[column_list].replace(99, np.nan)\n",
    "        grouped_cols = defaultdict(list)\n",
    "        for col in column_list:\n",
    "            prefix = col[:-1]\n",
    "            grouped_cols[prefix].append(col)\n",
    "        \n",
    "        feature_series_list = []\n",
    "        for prefix, columns in grouped_cols.items():\n",
    "            tooth_data = data_for_agg[columns]\n",
    "            max_values = tooth_data.max(axis=1).fillna(np.nan)\n",
    "            max_values.name = f'{prefix}_max'\n",
    "            feature_series_list.append(max_values)\n",
    "        \n",
    "        if feature_series_list:\n",
    "            X_max = pd.concat(feature_series_list, axis=1)\n",
    "        else:\n",
    "            X_max = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        return X_max\n",
    "\n",
    "    def get_combined_feature_set(self, df):\n",
    "        X_pd_max = self._create_max_features(df, self.pd_columns, \"PD\")\n",
    "        print(f\"PD features shape: {X_pd_max.shape}\")\n",
    "        \n",
    "        X_cal_max = self._create_max_features(df, self.cal_columns, \"CAL\")\n",
    "        print(f\"CAL features shape: {X_cal_max.shape}\")\n",
    "        \n",
    "        if X_pd_max.empty and X_cal_max.empty:\n",
    "            X_combined_max = pd.DataFrame(index=df.index)\n",
    "        elif X_pd_max.empty:\n",
    "            X_combined_max = X_cal_max.copy()\n",
    "        elif X_cal_max.empty:\n",
    "            X_combined_max = X_pd_max.copy()\n",
    "        else:\n",
    "            X_pd_max = X_pd_max.reindex(df.index)\n",
    "            X_cal_max = X_cal_max.reindex(df.index)\n",
    "            X_combined_max = pd.concat([X_pd_max, X_cal_max], axis=1)\n",
    "        \n",
    "        print(f\"Combined features shape: {X_combined_max.shape}\")\n",
    "        \n",
    "        y = df[Config.TARGET_COLUMN]\n",
    "        sample_weights = df[Config.WEIGHT_COLUMN] if Config.WEIGHT_COLUMN in df.columns else None\n",
    "        return X_combined_max, y, sample_weights\n",
    "\n",
    "    def nhanes_to_fdi(self, nhanes_tooth):\n",
    "        return Config.NHANES_TO_FDI_MAPPING.get(nhanes_tooth, nhanes_tooth)\n",
    "\n",
    "    def extract_tooth_numbers_from_features(self, feature_list):\n",
    "        tooth_numbers_fdi = set()\n",
    "        for feature in feature_list:\n",
    "            if 'OHX' in feature and ('PC_max' in feature or 'LA_max' in feature):\n",
    "                tooth_num = feature.replace('OHX', '').replace('PC_max', '').replace('LA_max', '')\n",
    "                if tooth_num.isdigit():\n",
    "                    fdi_num = self.nhanes_to_fdi(tooth_num)\n",
    "                    tooth_numbers_fdi.add(fdi_num)\n",
    "        return sorted(list(tooth_numbers_fdi))\n",
    "\n",
    "# ================== Bayesian Hyperparameter Tuning ==================\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self, cv_folds=5, random_state=42):\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def tune_model_bayes(self, model_name, base_model, X, y, sample_weight, param_space, scoring='roc_auc_ovr'):\n",
    "        print(f\"  Tuning hyperparameters for {model_name} with Bayesian Optimization...\")\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        bayes_search = BayesSearchCV(\n",
    "            base_model, param_space, n_iter=Config.BAYESIAN_N_ITER, \n",
    "            cv=cv, scoring=scoring, n_jobs=-1, random_state=self.random_state, verbose=0\n",
    "        )\n",
    "        \n",
    "        fit_params = {}\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            class_sample_weights = compute_sample_weight(\n",
    "                class_weight='balanced', \n",
    "                y=y\n",
    "            )\n",
    "            combined_weights = sample_weight * class_sample_weights\n",
    "            fit_params['sample_weight'] = combined_weights\n",
    "        else:\n",
    "            class_sample_weights = compute_sample_weight(\n",
    "                class_weight='balanced', \n",
    "                y=y\n",
    "            )\n",
    "            fit_params['sample_weight'] = class_sample_weights\n",
    "                \n",
    "            print(f\"    Applied class balancing during hyperparameter tuning for {model_name}\")\n",
    "\n",
    "        bayes_search.fit(X, y, **fit_params)\n",
    "            \n",
    "        tuned_model = base_model.set_params(**bayes_search.best_params_)\n",
    "        print(f\"    Best params: {bayes_search.best_params_}\")\n",
    "        print(f\"    Best score: {bayes_search.best_score_:.4f}\")\n",
    "        gc.collect()\n",
    "        return tuned_model, bayes_search.best_params_\n",
    "\n",
    "# ================== Multi-Seed Stability Analyzer ==================\n",
    "class MultiSeedStabilityAnalyzer:\n",
    "    def __init__(self, data_processor, random_seeds=Config.RANDOM_SEEDS):\n",
    "        self.data_processor = data_processor\n",
    "        self.random_seeds = random_seeds\n",
    "        self.stability_results = {}\n",
    "        self.all_run_shap_values = defaultdict(list)\n",
    "\n",
    "    def analyze_top_teeth_stability(self, X_train, y_train, sample_weights, model_name, best_params, current_output_dir):\n",
    "\n",
    "        import contextlib, io, sys\n",
    "        print(f\"\\n--- Analyzing Feature Stability for {model_name} (Robust Multi-Run SHAP) ---\")\n",
    "        \n",
    "        if not SHAP_AVAILABLE:\n",
    "            print(\"SHAP is not available. Skipping stability analysis.\")\n",
    "            return {}\n",
    "\n",
    "        self.all_run_shap_values.clear()\n",
    "\n",
    "        print(f\"Creating a fixed background sample of size {Config.SHAP_SAMPLE_SIZE} for SHAP analysis.\")\n",
    "        X_sample = X_train.sample(min(len(X_train), Config.SHAP_SAMPLE_SIZE), random_state=42)\n",
    "\n",
    "        total_runs = len(self.random_seeds) * Config.CV_FOLDS\n",
    "        run_count = 0\n",
    "\n",
    "        for seed_idx, seed in enumerate(self.random_seeds):\n",
    "            print(f\"\\n  Processing Seed {seed_idx + 1}/{len(self.random_seeds)}: {seed}\")\n",
    "            cv = StratifiedKFold(n_splits=Config.CV_FOLDS, shuffle=True, random_state=seed)\n",
    "            \n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "                run_count += 1\n",
    "                print(f\"    Fold {fold_idx + 1}/{Config.CV_FOLDS} (Overall Run {run_count}/{total_runs})\")\n",
    "\n",
    "                X_train_sub, _ = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_train_sub, _ = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                \n",
    "                sw_train_sub = sample_weights.iloc[train_idx] if sample_weights is not None else None\n",
    "                \n",
    "                model = create_model(model_name, random_state=seed)\n",
    "                model.set_params(**best_params)\n",
    "                \n",
    "                fit_params = {}\n",
    "\n",
    "                class_sample_weights = compute_sample_weight('balanced', y=y_train_sub)\n",
    "                fit_params['sample_weight'] = sw_train_sub * class_sample_weights if sw_train_sub is not None else class_sample_weights\n",
    "                model.set_params(verbosity=0)\n",
    "                \n",
    "                with contextlib.redirect_stdout(io.StringIO()):\n",
    "                    model.fit(X_train_sub, y_train_sub, **fit_params)\n",
    "                \n",
    "                try:\n",
    "                    explainer = shap.TreeExplainer(model, model_output=\"probability\", feature_perturbation=\"interventional\")\n",
    "                except Exception:\n",
    "                    explainer = shap.TreeExplainer(model)\n",
    "                shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "                if isinstance(shap_values, list):\n",
    "                    mean_shap = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)\n",
    "                else:\n",
    "                    mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "                for feature_name, shap_val in zip(X_train.columns, mean_shap):\n",
    "                    self.all_run_shap_values[feature_name].append(shap_val)\n",
    "                \n",
    "                del model, explainer, shap_values\n",
    "                gc.collect()\n",
    "        \n",
    "        stability_analysis = self._calculate_and_visualize_stability_results(model_name, current_output_dir)\n",
    "        self.stability_results[model_name] = stability_analysis\n",
    "        return stability_analysis\n",
    "\n",
    "    def _calculate_and_visualize_stability_results(self, model_name, current_output_dir):\n",
    "\n",
    "        print(f\"\\n  Aggregating and analyzing SHAP results for {model_name}...\")\n",
    "        \n",
    "        feature_stability_data = [{'feature': f, 'mean_shap': np.mean(s), 'std_shap': np.std(s)} \n",
    "                                  for f, s in self.all_run_shap_values.items()]\n",
    "        feature_df = pd.DataFrame(feature_stability_data).sort_values('mean_shap', ascending=False)\n",
    "\n",
    "        detailed_importance_data = []\n",
    "        for _, row in feature_df.iterrows():\n",
    "            match = re.search(r'OHX(\\d{2})(PC|LA)_max', row['feature'])\n",
    "            if match:\n",
    "                nhanes_num = match.group(1)\n",
    "                measurement_type = 'PD' if match.group(2) == 'PC' else 'CAL'\n",
    "                fdi_num = self.data_processor.nhanes_to_fdi(nhanes_num)\n",
    "                \n",
    "                detailed_importance_data.append({\n",
    "                    'tooth_fdi': fdi_num,\n",
    "                    'measurement_type': measurement_type,\n",
    "                    'feature': row['feature'],\n",
    "                    'mean_shap': row['mean_shap'],\n",
    "                    'shap_error': row['std_shap']\n",
    "                })\n",
    "        detailed_importance_df = pd.DataFrame(detailed_importance_data)\n",
    "\n",
    "        tooth_df_aggregated = detailed_importance_df.groupby('tooth_fdi').agg(\n",
    "            total_mean_shap=('mean_shap', 'sum'),\n",
    "            shap_error=('shap_error', 'mean')\n",
    "        ).sort_values('total_mean_shap', ascending=False).reset_index()\n",
    "\n",
    "        print(\"\\n--- Full Tooth Importance Ranking (Aggregated) ---\")\n",
    "        print(tooth_df_aggregated.to_string(index=False))\n",
    "\n",
    "        detailed_importance_df.to_csv(current_output_dir / f\"{model_name}_detailed_feature_importance.csv\", index=False)\n",
    "        tooth_df_aggregated.to_csv(current_output_dir / f\"{model_name}_aggregated_tooth_importance.csv\", index=False)\n",
    "        print(f\"\\nSaved detailed and aggregated importance to: {current_output_dir}\")\n",
    "\n",
    "        self.visualize_detailed_importance(detailed_importance_df, tooth_df_aggregated, model_name, current_output_dir)\n",
    "\n",
    "        analysis = {\n",
    "            'tooth_level_importance': tooth_df_aggregated,\n",
    "            'feature_level_stability': feature_df,\n",
    "            'detailed_importance': detailed_importance_df\n",
    "        }\n",
    "        return analysis\n",
    "\n",
    "    def visualize_detailed_importance(self, detailed_df, aggregated_df, model_name, current_output_dir):\n",
    "\n",
    "        print(f\"Generating detailed visualizations for {model_name}...\")\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                pass  # Use default style if seaborn styles not available\n",
    "\n",
    "        # Paired Bar Chart (PD vs. CAL)\n",
    "        top_teeth = aggregated_df.head(10)['tooth_fdi'].tolist()\n",
    "        plot_data = detailed_df[detailed_df['tooth_fdi'].isin(top_teeth)]\n",
    "\n",
    "        pivot_df = plot_data.pivot_table(index='tooth_fdi', columns='measurement_type', values='mean_shap').fillna(0)\n",
    "        pivot_df = pivot_df.reindex(top_teeth)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18, 9))\n",
    "        \n",
    "        bar_width = 0.35\n",
    "        index = np.arange(len(pivot_df.index))\n",
    "\n",
    "        bars1 = ax.bar(index - bar_width/2, pivot_df['PD'], bar_width, label='PD (Probing Depth)', color='royalblue')\n",
    "        \n",
    "        bars2 = ax.bar(index + bar_width/2, pivot_df['CAL'], bar_width, label='CAL (Clinical Attachment Level)', color='skyblue')\n",
    "\n",
    "        ax.set_ylabel('Robust Mean(|SHAP|) Value', fontsize=14)\n",
    "        ax.set_xlabel('Tooth (FDI Notation)', fontsize=14)\n",
    "        ax.set_title(f'PD vs. CAL Importance for Top 10 Teeth - {model_name}', fontsize=16, pad=20)\n",
    "        ax.set_xticks(index)\n",
    "        ax.set_xticklabels(pivot_df.index, rotation=45, ha=\"right\")\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        output_path_paired = current_output_dir / f\"{model_name}_paired_importance_barchart.png\"\n",
    "        plt.savefig(output_path_paired, dpi=800)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved paired bar chart to: {output_path_paired}\")\n",
    "\n",
    "        # Dental Heatmap\n",
    "        FDI_LAYOUT = {'18':(0,0),'17':(0,1),'16':(0,2),'15':(0,3),'14':(0,4),'13':(0,5),'12':(0,6),'11':(0,7),\n",
    "                    '21':(0,8),'22':(0,9),'23':(0,10),'24':(0,11),'25':(0,12),'26':(0,13),'27':(0,14),'28':(0,15),\n",
    "                    '48':(1,0),'47':(1,1),'46':(1,2),'45':(1,3),'44':(1,4),'43':(1,5),'42':(1,6),'41':(1,7),\n",
    "                    '31':(1,8),'32':(1,9),'33':(1,10),'34':(1,11),'35':(1,12),'36':(1,13),'37':(1,14),'38':(1,15)}\n",
    "        heatmap_data = np.full((2, 16), np.nan)\n",
    "        \n",
    "        importance_dict = aggregated_df.set_index('tooth_fdi')['total_mean_shap'].to_dict()\n",
    "        for fdi, pos in FDI_LAYOUT.items():\n",
    "            if fdi in importance_dict:\n",
    "                heatmap_data[pos] = importance_dict[fdi]\n",
    "\n",
    "        fig = plt.figure(figsize=(16, 6))\n",
    "        ax1 = fig.add_axes([0.05, 0.35, 0.9, 0.55])\n",
    "        im = ax1.imshow(heatmap_data, cmap='Reds', interpolation='nearest', aspect='auto')\n",
    "        cbar = fig.colorbar(im, ax=ax1, fraction=0.02, pad=0.04)\n",
    "        cbar.set_label('Aggregated Robust Mean(|SHAP|)', rotation=270, labelpad=15)\n",
    "\n",
    "        for fdi, pos in FDI_LAYOUT.items():\n",
    "            row, col = pos\n",
    "            val = heatmap_data[row, col]\n",
    "            if not np.isnan(val):\n",
    "                txt_color = 'white' if val > np.nanmax(heatmap_data)/2 else 'black'\n",
    "                ax1.text(col, row - 0.15, fdi, ha='center', va='center', color=txt_color, weight='bold', fontsize=12)\n",
    "                importance_str = f\"{val:.3f}\"\n",
    "                ax1.text(col, row + 0.15, importance_str, ha='center', va='center', color=txt_color, fontsize=10)\n",
    "\n",
    "        ax1.set_title(f'Aggregated Tooth Importance Heatmap for {model_name}', fontsize=16, pad=10)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "\n",
    "        output_path_heatmap = current_output_dir / f\"{model_name}_aggregated_importance_heatmap_with_values.png\"\n",
    "        fig.savefig(output_path_heatmap, dpi=800, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved heatmap with value table to: {output_path_heatmap}\")\n",
    "\n",
    "# ================== Model Evaluation Pipeline ==================\n",
    "class ModelPipeline:\n",
    "    def __init__(self, random_seeds=Config.RANDOM_SEEDS, cv_folds=Config.CV_FOLDS):\n",
    "        self.random_seeds = random_seeds\n",
    "        self.cv_folds = cv_folds\n",
    "        self.tuner = HyperparameterTuner(cv_folds=cv_folds)\n",
    "        self.best_params_cache = {}\n",
    "\n",
    "    def _calculate_weighted_metrics(self, y_true, y_pred, y_pred_proba, sample_weight=None):\n",
    "        auc_macro = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='macro', sample_weight=sample_weight)\n",
    "        accuracy = accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro', sample_weight=sample_weight)\n",
    "        qwk = cohen_kappa_score(y_true, y_pred, weights='quadratic', sample_weight=sample_weight)\n",
    "        return {'auc_macro': auc_macro, 'accuracy': accuracy, 'f1_macro': f1_macro, 'qwk': qwk}\n",
    "\n",
    "    def tune_hyperparameters_once(self, model_name, X, y, sample_weight, feature_set_name='Combined'):\n",
    "        param_key = f\"{model_name}_{feature_set_name}\"\n",
    "        if param_key in self.best_params_cache:\n",
    "            print(f\"  Using cached hyperparameters for {param_key}\")\n",
    "            return self.best_params_cache[param_key]\n",
    "        \n",
    "        if model_name in Config.BAYESIAN_HYPERPARAMETER_SPACES and SKOPT_AVAILABLE:\n",
    "            base_model = create_model(model_name)\n",
    "            _, best_params = self.tuner.tune_model_bayes(\n",
    "                model_name, base_model, X, y, sample_weight, \n",
    "                Config.BAYESIAN_HYPERPARAMETER_SPACES[model_name]\n",
    "            )\n",
    "            self.best_params_cache[param_key] = best_params\n",
    "            del base_model\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(f\"  Skipping Bayesian tuning for {model_name} (scikit-optimize not available or not configured). Using default parameters.\")\n",
    "            best_params = {}\n",
    "            self.best_params_cache[param_key] = best_params\n",
    "        return best_params\n",
    "\n",
    "    def evaluate_feature_sets_multiseed(self, X, y, sample_weights, model_name, best_params, stability_analyzer, current_output_dir):\n",
    "        print(f\"\\n{'='*50}\\nMULTI-SEED EVALUATION: {model_name}\\n{'='*50}\")\n",
    "        all_results = []\n",
    "\n",
    "        # SHAP stability analysis\n",
    "        stability_results = stability_analyzer.analyze_top_teeth_stability(\n",
    "            X, y, sample_weights, model_name, best_params, current_output_dir\n",
    "        )\n",
    "        \n",
    "        # Create feature sets based on stability results\n",
    "        if 'tooth_level_importance' in stability_results:\n",
    "            consensus_df = self._create_consensus_feature_sets(X, stability_results, model_name).get('SHAP_Consensus', pd.DataFrame())\n",
    "        else:\n",
    "            consensus_df = pd.DataFrame()\n",
    "\n",
    "        # Define feature sets\n",
    "        feature_sets = {\n",
    "            'Combined': X,\n",
    "            'CPI': self._get_clinical_index_features(X, 'CPI'),\n",
    "            'Ramfjord': self._get_clinical_index_features(X, 'Ramfjord'),\n",
    "            f'SHAP_Consensus_{model_name}': consensus_df\n",
    "        }\n",
    "\n",
    "        # Evaluate each feature set\n",
    "        roc_data = {}\n",
    "        for fs_name, X_fs in feature_sets.items():\n",
    "            if X_fs.empty:\n",
    "                print(f\"Skipping {fs_name} (no features)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n>>> Tuning {model_name} / {fs_name} ...\")\n",
    "            cache_name = 'SHAP_Consensus' if fs_name.startswith('SHAP_Consensus_') else fs_name\n",
    "            best_params_fs = self.tune_hyperparameters_once(\n",
    "                model_name, X_fs, y, sample_weights,\n",
    "                feature_set_name=cache_name\n",
    "            )\n",
    "\n",
    "            print(f\"\\nEvaluating {fs_name} ({X_fs.shape[1]} features)...\")\n",
    "            metrics_across_seeds, roc_curves = self._evaluate_with_multiseed_cv(\n",
    "                X_fs, y, sample_weights, model_name, best_params_fs\n",
    "            )\n",
    "\n",
    "            for metric, vals in metrics_across_seeds.items():\n",
    "                all_results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Feature_Set': fs_name,\n",
    "                    'Metric': metric,\n",
    "                    'Mean': np.mean(vals),\n",
    "                    'Std': np.std(vals),\n",
    "                    'N_Features': X_fs.shape[1]\n",
    "                })\n",
    "\n",
    "            roc_data[fs_name] = roc_curves\n",
    "\n",
    "        # Create ROC plots\n",
    "        n_feature_sets = len([fs for fs in feature_sets.values() if not fs.empty])\n",
    "        if n_feature_sets > 0:\n",
    "            fig, axes = plt.subplots(1,3, figsize=(4, 12))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for idx, class_label in enumerate(Config.CLASS_LABELS.values()):\n",
    "                ax = axes[idx]\n",
    "                \n",
    "                colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "                color_idx = 0\n",
    "                \n",
    "                for fs_name, curves in roc_data.items():\n",
    "                    fpr_tpr_list = curves[class_label]\n",
    "                    all_fpr = np.unique(np.concatenate([fpr for fpr, _ in fpr_tpr_list]))\n",
    "                    mean_tpr = np.zeros_like(all_fpr)\n",
    "                    for fpr, tpr in fpr_tpr_list:\n",
    "                        mean_tpr += np.interp(all_fpr, fpr, tpr)\n",
    "                    mean_tpr /= len(fpr_tpr_list)\n",
    "                    mean_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "                    display_name = fs_name\n",
    "                    if fs_name.startswith('SHAP_Consensus_'):\n",
    "                        display_name = f\"SHAP_{model_name}\"\n",
    "                    \n",
    "                    ax.plot(all_fpr, mean_tpr,\n",
    "                            label=f\"{display_name} (AUC={mean_auc:.2f})\",\n",
    "                            linewidth=2,\n",
    "                            color=colors[color_idx % len(colors)])\n",
    "                    color_idx += 1\n",
    "\n",
    "                ax.plot([0,1],[0,1],'--', color='gray', alpha=0.5)\n",
    "                ax.set_title(f\"{class_label} - {model_name}\")\n",
    "                ax.set_xlabel(\"False Positive Rate\")\n",
    "                ax.set_ylabel(\"True Positive Rate\")\n",
    "                ax.legend(loc=\"lower right\", fontsize='small')\n",
    "\n",
    "            fig.suptitle(f\"{model_name} - Cross-validation ROC-AUC (Training Set)\", fontsize=16)\n",
    "            fig.tight_layout(rect=[0,0,1,0.96])\n",
    "            out_path = Config.OUTPUT_DIR / f\"roc_group_{model_name}_train.png\"\n",
    "            fig.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f\"Saved grouped ROC figure: {out_path}\")\n",
    "\n",
    "        return all_results, stability_results\n",
    "\n",
    "    def _create_consensus_feature_sets(self, X_full, stability_results, model_name):\n",
    "        feature_sets = {}\n",
    "\n",
    "        if 'tooth_level_importance' in stability_results:\n",
    "            tooth_df = stability_results['tooth_level_importance']\n",
    "            top_teeth_fdi = tooth_df.head(Config.TOP_FEATURES_COUNT)['tooth_fdi'].tolist()\n",
    "\n",
    "            shap_features = []\n",
    "            for tooth_fdi in top_teeth_fdi:\n",
    "                nhanes_tooth = next((nhanes for nhanes, fdi in Config.NHANES_TO_FDI_MAPPING.items() if fdi == tooth_fdi), None)\n",
    "                if nhanes_tooth:\n",
    "                    for p_type in ['PC', 'LA']:\n",
    "                        feature = f'OHX{nhanes_tooth}{p_type}_max'\n",
    "                        if feature in X_full.columns:\n",
    "                            shap_features.append(feature)\n",
    "\n",
    "            if shap_features:\n",
    "                key = 'SHAP_Consensus'\n",
    "                feature_sets[key] = X_full[shap_features]\n",
    "                print(f\"  Created {key} from robust ranking with teeth: {sorted(top_teeth_fdi)}\")\n",
    "\n",
    "        feature_sets['CPI_Reference'] = self._get_clinical_index_features(X_full, 'CPI')\n",
    "        feature_sets['Ramfjord_Reference'] = self._get_clinical_index_features(X_full, 'Ramfjord')\n",
    "\n",
    "        return feature_sets\n",
    "\n",
    "    def _get_clinical_index_features(self, X_combined, method_name):\n",
    "        fdi_numbers = Config.CPI_RAMFJORD_TOOTH_NUMBERS[method_name]\n",
    "        selected_features = []\n",
    "        for fdi_num in fdi_numbers:\n",
    "            nhanes_num = next((nhanes for nhanes, fdi in Config.NHANES_TO_FDI_MAPPING.items() if fdi == fdi_num), None)\n",
    "            if nhanes_num:\n",
    "                for p_type in ['PC', 'LA']:\n",
    "                    feature = f'OHX{nhanes_num}{p_type}_max'\n",
    "                    if feature in X_combined.columns: selected_features.append(feature)\n",
    "        \n",
    "        return X_combined[selected_features] if selected_features else pd.DataFrame()\n",
    "\n",
    "    def _evaluate_with_multiseed_cv(self, X, y, sample_weights, model_name, best_params):\n",
    "        all_metrics = defaultdict(list)\n",
    "        roc_curves = {cls: [] for cls in Config.CLASS_LABELS.values()}\n",
    "\n",
    "        classes = list(Config.CLASS_LABELS.keys())\n",
    "        y_bin_full = label_binarize(y, classes=classes)\n",
    "\n",
    "        for seed in self.random_seeds:\n",
    "            cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=seed)\n",
    "            for train_idx, val_idx in cv.split(X, y):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                w_train = sample_weights.iloc[train_idx] if sample_weights is not None else None\n",
    "                w_val   = sample_weights.iloc[val_idx]   if sample_weights is not None else None\n",
    "\n",
    "                model = create_model(model_name, random_state=seed)\n",
    "                model.set_params(**best_params)\n",
    "\n",
    "                fit_params = {}\n",
    "                \n",
    "                class_sample_weights = compute_sample_weight(\n",
    "                    class_weight='balanced', \n",
    "                    y=y_train\n",
    "                )\n",
    "                \n",
    "                if w_train is not None:\n",
    "                    combined_weights = w_train * class_sample_weights\n",
    "                    fit_params['sample_weight'] = combined_weights\n",
    "                else:\n",
    "                    fit_params['sample_weight'] = class_sample_weights\n",
    "\n",
    "                model.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "                y_score = model.predict_proba(X_val)\n",
    "                y_val_bin = y_bin_full[val_idx, :]\n",
    "\n",
    "                for i, class_name in enumerate(Config.CLASS_LABELS.values()):\n",
    "                    fpr_i, tpr_i, _ = roc_curve(\n",
    "                        y_val_bin[:, i],\n",
    "                        y_score[:, i],\n",
    "                        sample_weight=w_val\n",
    "                    )\n",
    "                    roc_curves[class_name].append((fpr_i, tpr_i))\n",
    "\n",
    "                metrics = self._calculate_weighted_metrics(\n",
    "                    y_val, model.predict(X_val), y_score, w_val\n",
    "                )\n",
    "                for name, v in metrics.items():\n",
    "                    all_metrics[name].append(v)\n",
    "\n",
    "        return all_metrics, roc_curves\n",
    "\n",
    "def plot_separate_test_rocs(all_test_predictions, model_names):\n",
    "    \"\"\"Plot ROC curves for each model separately\"\"\"\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_entries = [e for e in all_test_predictions if e['model_name'] == model_name]\n",
    "        if not model_entries:\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(1,3, figsize=(4, 12))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for idx, class_label in enumerate(Config.CLASS_LABELS.values()):\n",
    "            ax = axes[idx]\n",
    "            colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "            color_idx = 0\n",
    "\n",
    "            for entry in model_entries:\n",
    "                feature_set = entry['feature_set']\n",
    "                y_score = entry['y_score']\n",
    "                y_true = entry['y_true']\n",
    "                sample_weight = entry.get('sample_weight', None)\n",
    "\n",
    "                classes = list(Config.CLASS_LABELS.keys())\n",
    "                y_true_bin = label_binarize(y_true, classes=classes)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(\n",
    "                    y_true_bin[:, idx],\n",
    "                    y_score[:, idx],\n",
    "                    sample_weight=sample_weight\n",
    "                )\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                display_name = feature_set\n",
    "                if feature_set.startswith('SHAP_Consensus_'):\n",
    "                    display_name = \"SHAP_Consensus\"\n",
    "\n",
    "                ax.plot(fpr, tpr,\n",
    "                        label=f\"{display_name} (AUC={roc_auc:.2f})\",\n",
    "                        linewidth=2,\n",
    "                        color=colors[color_idx % len(colors)])\n",
    "                color_idx += 1\n",
    "\n",
    "            ax.plot([0, 1], [0, 1], '--', color='gray', alpha=0.5)\n",
    "            ax.set_title(class_label, fontsize=14)\n",
    "            ax.set_xlabel(\"False Positive Rate\")\n",
    "            ax.set_ylabel(\"True Positive Rate\")\n",
    "            ax.legend(fontsize='small', loc='lower right')\n",
    "\n",
    "        fig.suptitle(f\"{model_name} - Test Set ROC Curves by Disease Severity\", fontsize=16)\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        output_path = Config.OUTPUT_DIR / f\"roc_test_{model_name}_by_severity.png\"\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved test ROC figure for {model_name}: {output_path}\")\n",
    "\n",
    "def evaluate_on_test_set(pipeline, stability_analyzer, model_names, X_train_full, X_test, y_train_full, y_test, sw_train_full, sw_test):\n",
    "    final_test_results = []\n",
    "    all_test_predictions = []\n",
    "\n",
    "    for model_name in model_names:\n",
    "        stability_results = stability_analyzer.stability_results.get(model_name, {})\n",
    "\n",
    "        # Rebuild feature sets\n",
    "        feature_sets = {\n",
    "            'Combined': X_train_full,\n",
    "            'CPI': pipeline._get_clinical_index_features(X_train_full, 'CPI'),\n",
    "            'Ramfjord': pipeline._get_clinical_index_features(X_train_full, 'Ramfjord')\n",
    "        }\n",
    "        \n",
    "        # Add SHAP consensus if available\n",
    "        consensus_key = f'SHAP_Consensus_{model_name}'\n",
    "        consensus_df = pd.DataFrame()\n",
    "        if 'tooth_level_importance' in stability_results:\n",
    "            consensus_df = pipeline._create_consensus_feature_sets(\n",
    "                X_train_full, stability_results, model_name\n",
    "            ).get('SHAP_Consensus', pd.DataFrame())\n",
    "        feature_sets[consensus_key] = consensus_df\n",
    "\n",
    "        for feature_set_name, X_fs_train in feature_sets.items():\n",
    "            if X_fs_train.empty:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nEvaluating {model_name} / {feature_set_name} on test set...\")\n",
    "\n",
    "            # Get cached parameters\n",
    "            cache_name = 'SHAP_Consensus' if feature_set_name.startswith('SHAP_Consensus_') else feature_set_name\n",
    "            param_key = f\"{model_name}_{cache_name}\"\n",
    "            best_params = pipeline.best_params_cache.get(param_key, {})\n",
    "\n",
    "            X_fs_test = X_test.reindex(columns=X_fs_train.columns)\n",
    "            if X_fs_test.isna().any().any():\n",
    "                nan_counts = X_fs_test.isna().sum()\n",
    "                missing_info = nan_counts[nan_counts > 0].to_dict()\n",
    "                print(f\"  Warning: Test set for {model_name}/{feature_set_name} has NaNs in columns (filling with 0): {missing_info}\")\n",
    "                X_fs_test = X_fs_test.fillna(0)\n",
    "\n",
    "            # Train final model\n",
    "            model = create_model(model_name, random_state=42)\n",
    "            model.set_params(**best_params)\n",
    "\n",
    "            fit_params = {}\n",
    "\n",
    "            class_sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_full)\n",
    "            if sw_train_full is not None:\n",
    "                combined_weights = sw_train_full * class_sample_weights\n",
    "                fit_params['sample_weight'] = combined_weights\n",
    "            else:\n",
    "                fit_params['sample_weight'] = class_sample_weights\n",
    "\n",
    "            model.fit(X_fs_train, y_train_full, **fit_params)\n",
    "\n",
    "            # Predictions\n",
    "            y_pred = model.predict(X_fs_test)\n",
    "            y_pred_proba = model.predict_proba(X_fs_test)\n",
    "\n",
    "            # Metrics\n",
    "            test_metrics = pipeline._calculate_weighted_metrics(\n",
    "                y_test, y_pred, y_pred_proba, sw_test\n",
    "            )\n",
    "            for metric_name, metric_value in test_metrics.items():\n",
    "                final_test_results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Feature_Set': feature_set_name,\n",
    "                    'Metric': metric_name,\n",
    "                    'Test_Score': metric_value,\n",
    "                    'N_Features': X_fs_train.shape[1]\n",
    "                })\n",
    "\n",
    "            print(f\"  {feature_set_name} ({X_fs_train.shape[1]} features): \"\n",
    "                  f\"AUC={test_metrics['auc_macro']:.3f}, \"\n",
    "                  f\"Acc={test_metrics['accuracy']:.3f}, \"\n",
    "                  f\"QWK={test_metrics['qwk']:.3f}\")\n",
    "\n",
    "            all_test_predictions.append({\n",
    "                'model_name': model_name,\n",
    "                'feature_set': feature_set_name,\n",
    "                'y_score': y_pred_proba,\n",
    "                'y_true': y_test,\n",
    "                'sample_weight': sw_test\n",
    "            })\n",
    "\n",
    "    return final_test_results, all_test_predictions\n",
    "\n",
    "# ================== Main Execution ==================\n",
    "def main():\n",
    "    print(\"=\"*80 + \"\\nMULTI-SEED TEETH STABILITY ANALYSIS (SHAP-FOCUSED, v8)\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Check for required libraries\n",
    "    if not XGB_AVAILABLE and not LGB_AVAILABLE:\n",
    "        print(\"ERROR: Neither XGBoost nor LightGBM is available. Please install at least one.\")\n",
    "        return\n",
    "    \n",
    "    data_processor = DataProcessor()\n",
    "    df = data_processor.load_and_preprocess(Config.DATA_PATH)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Execution halted due to missing data file.\")\n",
    "        return\n",
    "\n",
    "    X_combined_unscaled, y, sample_weights = data_processor.get_combined_feature_set(df)\n",
    "\n",
    "    X_combined_scaled = X_combined_unscaled  # no scaling for tree models\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\nDATA SPLITTING\\n\" + \"=\"*60)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X_combined_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    sw_train_full, sw_test = (None, None)\n",
    "    if sample_weights is not None:\n",
    "        sw_train_full, sw_test = train_test_split(\n",
    "            sample_weights, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    else:\n",
    "        sw_train_full, sw_test = None, None\n",
    "        \n",
    "    #save test set\n",
    "    test_idx = X_test.index\n",
    "    test_full = df.loc[test_idx].copy()\n",
    "\n",
    "    test_full[\"label_name\"] = test_full[Config.TARGET_COLUMN].map(Config.CLASS_LABELS)\n",
    "\n",
    "    front = [Config.TARGET_COLUMN, \"label_name\", Config.WEIGHT_COLUMN, Config.AGE_COLUMN]\n",
    "    front_exist = [c for c in front if c in test_full.columns]\n",
    "    test_full = test_full[front_exist + [c for c in test_full.columns if c not in front_exist]]\n",
    "\n",
    "    test_csv_path = Config.OUTPUT_DIR / \"test_set_full.csv\"\n",
    "    test_full.to_csv(test_csv_path, index=False)\n",
    "    print(f\"Full test set saved to: {test_csv_path}\")\n",
    "\n",
    "\n",
    "    print(f\"Dataset sizes:\")\n",
    "    print(f\"  Training: {len(X_train_full):,} samples ({len(X_train_full)/len(X_combined_scaled)*100:.1f}%)\")\n",
    "    print(f\"  Test:     {len(X_test):,} samples ({len(X_test)/len(X_combined_scaled)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nClass distribution:\")\n",
    "    for split_name, y_split in [(\"Training\", y_train_full), (\"Test\", y_test)]:\n",
    "        dist = y_split.value_counts().sort_index()\n",
    "        dist_pct = (dist / len(y_split) * 100).round(1)\n",
    "        print(f\"  {split_name}: {dict(zip([Config.CLASS_LABELS[i] for i in dist.index], [f'{dist[i]} ({dist_pct[i]}%)' for i in dist.index]))}\")\n",
    "    \n",
    "    print(f\"\\nCross-validation setup:\")\n",
    "    print(f\"  Method: {Config.CV_FOLDS}-fold stratified cross-validation\")\n",
    "    print(f\"  Seeds: {len(Config.RANDOM_SEEDS)} different random seeds\")\n",
    "    print(f\"  Total CV runs: {Config.CV_FOLDS * len(Config.RANDOM_SEEDS)} per feature set per model\")\n",
    "    \n",
    "    model_names = [name for name, available in [('XGBoost', XGB_AVAILABLE), ('LightGBM', LGB_AVAILABLE)] if available]\n",
    "    print(f\"Available models: {model_names}\")\n",
    "\n",
    "    pipeline = ModelPipeline()\n",
    "    stability_analyzer = MultiSeedStabilityAnalyzer(data_processor)\n",
    "\n",
    "    all_results = []\n",
    "    all_stability_results = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n{'='*60}\\nPROCESSING MODEL: {model_name}\\n{'='*60}\")\n",
    "        best_params = pipeline.tune_hyperparameters_once(\n",
    "            model_name, X_train_full, y_train_full, sw_train_full\n",
    "        )\n",
    "        \n",
    "        model_results, stability_results = pipeline.evaluate_feature_sets_multiseed(\n",
    "            X_train_full, y_train_full, sw_train_full, model_name, best_params, stability_analyzer, Config.OUTPUT_DIR\n",
    "        )\n",
    "        \n",
    "        all_results.extend(model_results)\n",
    "        all_stability_results[model_name] = stability_results\n",
    "\n",
    "    # Final test set evaluation\n",
    "    final_test_results, all_test_predictions = evaluate_on_test_set(\n",
    "        pipeline, stability_analyzer,\n",
    "        model_names,\n",
    "        X_train_full, X_test,\n",
    "        y_train_full, y_test,\n",
    "        sw_train_full, sw_test\n",
    "    )\n",
    "\n",
    "    # Save cross-validation results\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_csv(Config.OUTPUT_DIR / \"cross_validation_results.csv\", index=False)\n",
    "    print(f\"Saved: cross_validation_results.csv\")\n",
    "\n",
    "    # Plot combined ROC curves\n",
    "    if all_test_predictions:\n",
    "        plot_separate_test_rocs(all_test_predictions, model_names)\n",
    "\n",
    "    # Save test results\n",
    "    if final_test_results:\n",
    "        test_results_df = pd.DataFrame(final_test_results)\n",
    "        test_results_df.to_csv(Config.OUTPUT_DIR / \"final_test_results.csv\", index=False)\n",
    "        print(f\"Saved: final_test_results.csv\")\n",
    "\n",
    "    # CV vs Test comparison\n",
    "    if final_test_results:\n",
    "        cv_summary = results_df.groupby(['Model', 'Feature_Set', 'Metric'])['Mean'].first().reset_index()\n",
    "        cv_summary = cv_summary.rename(columns={'Mean': 'CV_Score'})\n",
    "        comparison_df = pd.merge(\n",
    "            cv_summary,\n",
    "            test_results_df,\n",
    "            on=['Model', 'Feature_Set', 'Metric'],\n",
    "            how='outer'\n",
    "        )\n",
    "        comparison_df['Difference'] = comparison_df['Test_Score'] - comparison_df['CV_Score']\n",
    "        comparison_df['Overfitting'] = comparison_df['Difference'] < -0.01\n",
    "        comparison_df.to_csv(Config.OUTPUT_DIR / \"cv_vs_test_comparison.csv\", index=False)\n",
    "        print(f\"Saved: cv_vs_test_comparison.csv\")\n",
    "\n",
    "    # Update stability analyzer\n",
    "    stability_analyzer.stability_results = all_stability_results\n",
    "    \n",
    "    # Final consolidated summary\n",
    "    final_summary_data = []\n",
    "    for model_name, stability in all_stability_results.items():\n",
    "        if 'tooth_level_importance' not in stability: \n",
    "            continue\n",
    "        \n",
    "        tooth_ranking_df = stability['tooth_level_importance']\n",
    "        consensus_teeth = tooth_ranking_df.head(Config.TOP_FEATURES_COUNT)['tooth_fdi'].tolist()\n",
    "        \n",
    "        param_key = f\"{model_name}_Combined\"\n",
    "        params = pipeline.best_params_cache.get(param_key, {})\n",
    "        \n",
    "        test_perf = {}\n",
    "        if final_test_results:\n",
    "            test_df = pd.DataFrame(final_test_results)\n",
    "            combined_test = test_df[(test_df['Model'] == model_name) & (test_df['Feature_Set'] == 'Combined')]\n",
    "            for _, row in combined_test.iterrows():\n",
    "                test_perf[f\"Test_{row['Metric']}\"] = f\"{row['Test_Score']:.3f}\"\n",
    "        \n",
    "        shap_test_perf = {}\n",
    "        if final_test_results:\n",
    "            shap_test = test_df[(test_df['Model'] == model_name) & (test_df['Feature_Set'] == f'SHAP_Consensus_{model_name}')]\n",
    "            for _, row in shap_test.iterrows():\n",
    "                shap_test_perf[f\"SHAP_Test_{row['Metric']}\"] = f\"{row['Test_Score']:.3f}\"\n",
    "        \n",
    "        summary_row = {\n",
    "            'Model': model_name,\n",
    "            'Consensus_Teeth_FDI': ', '.join(map(str, sorted(consensus_teeth))) if consensus_teeth else 'None',\n",
    "            'N_Consensus_Teeth': len(consensus_teeth)\n",
    "        }\n",
    "        summary_row.update(params)\n",
    "        summary_row.update(test_perf)\n",
    "        summary_row.update(shap_test_perf)\n",
    "        final_summary_data.append(summary_row)\n",
    "\n",
    "    if final_summary_data:\n",
    "        final_summary_df = pd.DataFrame(final_summary_data).fillna('N/A')\n",
    "        base_cols = ['Model', 'Consensus_Teeth_FDI', 'N_Consensus_Teeth']\n",
    "        test_cols = sorted([c for c in final_summary_df.columns if c.startswith('Test_') or c.startswith('SHAP_Test_')])\n",
    "        param_cols = sorted([c for c in final_summary_df.columns if c not in base_cols + test_cols])\n",
    "        final_summary_df = final_summary_df[base_cols + test_cols + param_cols]\n",
    "        final_summary_df.to_csv(Config.OUTPUT_DIR / \"final_consolidated_summary.csv\", index=False)\n",
    "        print(\"Saved: final_consolidated_summary.csv\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\nANALYSIS COMPLETE\\n\" + \"=\"*80)\n",
    "    print(f\"All results, summaries, and plots have been saved to: {Config.OUTPUT_DIR}\")\n",
    "    print(\"\\nKey outputs:\")\n",
    "    print(\"- cross_validation_results.csv: Multi-seed cross-validation performance (on training set)\")\n",
    "    print(\"- final_test_results.csv: Unbiased test set performance\")  \n",
    "    print(\"- cv_vs_test_comparison.csv: Cross-validation vs test performance comparison\")\n",
    "    print(\"- final_consolidated_summary.csv: Complete summary with test scores\")\n",
    "    print(\"\\nData usage summary:\")\n",
    "    print(\"- Training set (80%): Used for hyperparameter tuning, cross-validation, and SHAP analysis\")\n",
    "    print(\"- Test set (20%): Used only for final unbiased evaluation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
